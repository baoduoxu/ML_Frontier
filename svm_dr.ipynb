{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed is set to 0.\n",
      "{'AD': 0, 'MCI': 1, 'MCIn': 2, 'MCIp': 3, 'NC': 4}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mg:\\dl\\ML_Frontier\\svm_dr.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# if __name__=='__main__':\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mfor\u001b[39;00m seed \u001b[39min\u001b[39;00m seeds:\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# X_train, y_train, X_valid, y_valid, X_test, y_test=[],[],[],[],[],[]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     X_train, y_train, X_valid, y_valid, X_test, y_test\u001b[39m=\u001b[39mdata_process(seed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m降维前的svm的表现:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/g%3A/dl/ML_Frontier/svm_dr.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     _svm(X_train,y_train,X_valid, y_valid,X_test,y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_process' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys,os\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # 添加上层目录到 sys.path\n",
    "# from data_process import data_process,Labels\n",
    "# from data_process import X_test,X_train\n",
    "# from data_process import y_test,y_train,Labels\n",
    "# from data_process import X_test_MCI,X_train_MCI,y_test_MCI,y_train_MCI\n",
    "# # from dimension_reduction import X_train,X_test\n",
    "from dimension_reduction_lda import dimension_reduction,visualization\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "dim=2\n",
    "\n",
    "def _svm(X_train,y_train,X_valid,y_valid,X_test,y_test):\n",
    "        clf=svm.SVC(kernel='linear',C=1.0,random_state=0,decision_function_shape='ovr')\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        train_acc=accuracy_score(y_train,clf.predict(X_train))\n",
    "        valid_acc=accuracy_score(y_valid,clf.predict(X_valid))\n",
    "        test_acc=accuracy_score(y_test,y_pred)\n",
    "        # print('train:',accuracy_score(y_train,clf.predict(X_train)))\n",
    "        # print('validation',accuracy_score(y_valid,clf.predict(X_valid)))\n",
    "        # print('test:',accuracy_score(y_test,clf.predict(X_test)))\n",
    "        # print(classification_report(y_test,y_pred,target_names=Labels))\n",
    "        return train_acc,valid_acc,test_acc\n",
    "seeds=[0,1,2,3,4]\n",
    "train_accs,valid_accs,test_accs=[],[],[]\n",
    "# if __name__=='__main__':\n",
    "for seed in seeds:\n",
    "    # X_train, y_train, X_valid, y_valid, X_test, y_test=[],[],[],[],[],[]\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test=data_process(seed)\n",
    "    print('降维前的svm的表现:')\n",
    "    _svm(X_train,y_train,X_valid, y_valid,X_test,y_test)\n",
    "    print('降维后svm的表现:')\n",
    "\n",
    "    X=np.concatenate((X_train,X_valid,X_test),axis=0)\n",
    "    y=np.concatenate((y_train,y_valid,y_test),axis=0)\n",
    "    X_reduced=dimension_reduction(X,y,dim=120,method='PCA')\n",
    "    X_train_reduced=X_reduced[:X_train.shape[0],:]\n",
    "    X_valid_reduced=X_reduced[X_train.shape[0]:X_train.shape[0]+X_valid.shape[0],:]\n",
    "    X_test_reduced=X_reduced[X_train.shape[0]+X_valid.shape[0]:,:]\n",
    "\n",
    "    # X_train_reduced=dimension_reduction(X_train_reduced,y_train,dim=30,method='Laplacian')\n",
    "    # X_train_reduced,proj_mat=dimension_reduction(X_train_reduced,y_train,dim=1,method='LDA')\n",
    "    # visualization(X_train_reduced,y_train,dim=dim,method='PCA',class_num=2)\n",
    "    # X_test_reduced=dimension_reduction(X_test,y_test,dim=2,method='Isomap')\n",
    "    # X_test_reduced=dimension_reduction(X_test_reduced,y_test,dim=30,method='Laplacian')\n",
    "    # X_test_reduced=np.dot(X_test_reduced,proj_mat)\n",
    "    # visualization(X_test_reduced,y_test,dim=dim,method='PCA',class_num=2)\n",
    "    # _svm(X_train_reduced,y_train,X_test_reduced,y_test)\n",
    "    train_acc,valid_acc,test_acc=_svm(X_train_reduced,y_train,X_valid_reduced,y_valid,X_test_reduced,y_test)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_accs.append(valid_acc)\n",
    "    test_accs.append(test_acc)\n",
    "print('train_accs:',train_accs)\n",
    "print('valid_accs:',valid_accs)\n",
    "print('test_accs:',test_accs)\n",
    "print('train_acc:',np.mean(train_accs),np.std(train_accs))\n",
    "print('valid_acc:',np.mean(valid_accs),np.std(valid_accs))\n",
    "print('test_acc:',np.mean(test_accs),np.std(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/PPMI.mat\n",
      "{'NC': 0, 'PD': 1}\n"
     ]
    }
   ],
   "source": [
    "# 读入.mat文件, 划分测试集与训练集\n",
    "\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# if len(sys.argv)!=2:\n",
    "#     print('Usage: python data_process.py <dataset_path>')\n",
    "#     sys.exit(1)\n",
    "\n",
    "# file_path=sys.argv[1]\n",
    "# file_path='dataset/ADNI.mat'\n",
    "file_path='dataset/PPMI.mat'\n",
    "mat_data=scipy.io.loadmat(file_path)\n",
    "print(file_path)\n",
    "# print(mat_data.keys())\n",
    "train_ratio=0.6\n",
    "valid_ratio=0.2\n",
    "test_ratio=0.2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Labels=[key for key in mat_data.keys() if not key.startswith('__')]\n",
    "dict_labels = {label: i for i, label in enumerate(Labels)}\n",
    "print(dict_labels)\n",
    "scaler=StandardScaler()\n",
    "\n",
    "\n",
    "import time\n",
    "import random\n",
    "# random_seed=int(time.time())\n",
    "\n",
    "def data_process(random_seed):\n",
    "    X_train=[]\n",
    "    X_test=[]\n",
    "    y_train=[]\n",
    "    y_test=[]\n",
    "    X_valid=[]\n",
    "    y_valid=[]\n",
    "    y_train_master=[] # 在主分类器中, 将 MCI, MCIn, MCIp 合并为一类的训练集标签\n",
    "    y_valid_master=[]\n",
    "    y_test_master=[]\n",
    "    X_train_MCI=[] # MCI, MCIn, MCIp 的训练集, 验证集及其标签\n",
    "    X_valid_MCI=[]\n",
    "    y_train_MCI=[]\n",
    "    y_valid_MCI=[]\n",
    "    X_test_MCI=[]\n",
    "    y_test_MCI=[]\n",
    "\n",
    "    print(f'random seed: {random_seed}')\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    for label,data in mat_data.items():\n",
    "        if label.startswith('__'):\n",
    "            continue\n",
    "        label_num=dict_labels[label]\n",
    "        N=np.shape(data)[0]\n",
    "        indices=np.random.permutation(N)\n",
    "        train_end = int(train_ratio * N)\n",
    "        valid_end = int((train_ratio + valid_ratio) * N)\n",
    "\n",
    "        train_index = indices[:train_end]\n",
    "        validation_index = indices[train_end:valid_end]\n",
    "        test_index = indices[valid_end:]\n",
    "        # print(indices)\n",
    "        # print(train_index,validation_index,test_index)\n",
    "        for i in range(N):\n",
    "            if i in train_index:\n",
    "                X_train.append(data[i])\n",
    "                y_train.append(label_num)\n",
    "                if file_path=='dataset/ADNI.mat' and label_num>=1 and label_num<=3:\n",
    "                    y_train_master.append(-1)\n",
    "                    X_train_MCI.append(data[i]) # MCI, MCIn, MCIp 的训练集\n",
    "                    y_train_MCI.append(label_num)\n",
    "                else:\n",
    "                    y_train_master.append(label_num)\n",
    "            if i in validation_index:\n",
    "                X_valid.append(data[i])\n",
    "                y_valid.append(label_num)\n",
    "                if file_path=='dataset/ADNI.mat' and label_num>=1 and label_num<=3:\n",
    "                    y_valid_master.append(-1)\n",
    "                    X_valid_MCI.append(data[i]) # MCI, MCIn, MCIp 的验证集\n",
    "                    y_valid_MCI.append(label_num)\n",
    "                else:\n",
    "                    y_valid_master.append(label_num)\n",
    "            if i in test_index:\n",
    "                X_test.append(data[i])\n",
    "                y_test.append(label_num)\n",
    "                if file_path=='dataset/ADNI.mat' and label_num>=1 and label_num<=3:\n",
    "                    y_test_master.append(-1)\n",
    "                    X_test_MCI.append(data[i]) # MCI, MCIn, MCIp 的测试集\n",
    "                    y_test_MCI.append(label_num)\n",
    "                else:\n",
    "                    y_test_master.append(label_num)\n",
    "                \n",
    "\n",
    "    dict_labels_MCI = {label: i for i, label in enumerate(Labels[1:])}\n",
    "    X_train = np.array(X_train)\n",
    "    y_train=np.array(y_train)\n",
    "    y_train_master=np.array(y_train_master)\n",
    "\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_valid=np.array(y_valid)\n",
    "    y_valid_master=np.array(y_valid_master)\n",
    "\n",
    "    X_train_MCI = np.array(X_train_MCI)\n",
    "    y_train_MCI=np.array(y_train_MCI)\n",
    "\n",
    "    X_valid_MCI = np.array(X_valid_MCI)\n",
    "    y_valid_MCI=np.array(y_valid_MCI)\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    y_test=np.array(y_test)\n",
    "    y_test_master=np.array(y_test_master)\n",
    "    def normalize(X):\n",
    "        if X!=[]:\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X)\n",
    "            # X=(X-np.mean(X,axis=0))/np.std(X,axis=0)\n",
    "        return X\n",
    "    Labels_MCI=[-1,0,4]\n",
    "    # X_train=normalize(X_train)\n",
    "    # X_valid=normalize(X_valid)\n",
    "    # X_train_MCI=normalize(X_train_MCI)\n",
    "    # X_valid_MCI=normalize(X_valid_MCI)\n",
    "    # X_test=normalize(X_test)\n",
    "    # X_test_MCI=normalize(X_test_MCI)\n",
    "    return X_train,y_train,X_valid,y_valid,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/PPMI.mat\n",
      "{'NC': 0, 'PD': 1}\n",
      "random seed: 0\n",
      "降维前的svm的表现:\n",
      "降维后svm的表现:\n",
      "before dimension reduction: (543, 294)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys,os\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))) # 添加上层目录到 sys.path\n",
    "# from data_process import data_process,Labels\n",
    "# from data_process import X_test,X_train\n",
    "# from data_process import y_test,y_train,Labels\n",
    "# from data_process import X_test_MCI,X_train_MCI,y_test_MCI,y_train_MCI\n",
    "# # from dimension_reduction import X_train,X_test\n",
    "from dimension_reduction_lda import dimension_reduction,visualization\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "dim=2\n",
    "\n",
    "def _svm(X_train,y_train,X_valid,y_valid,X_test,y_test):\n",
    "        clf=svm.SVC(kernel='linear',C=1.0,random_state=0,decision_function_shape='ovr')\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred=clf.predict(X_test)\n",
    "        train_acc=accuracy_score(y_train,clf.predict(X_train))\n",
    "        valid_acc=accuracy_score(y_valid,clf.predict(X_valid))\n",
    "        test_acc=accuracy_score(y_test,y_pred)\n",
    "        # print('train:',accuracy_score(y_train,clf.predict(X_train)))\n",
    "        # print('validation',accuracy_score(y_valid,clf.predict(X_valid)))\n",
    "        # print('test:',accuracy_score(y_test,clf.predict(X_test)))\n",
    "        # print(classification_report(y_test,y_pred,target_names=Labels))\n",
    "        return train_acc,valid_acc,test_acc\n",
    "seeds=[0,1,2,3,4]\n",
    "train_accs,valid_accs,test_accs=[],[],[]\n",
    "# if __name__=='__main__':\n",
    "for seed in seeds:\n",
    "    # X_train, y_train, X_valid, y_valid, X_test, y_test=[],[],[],[],[],[]\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test=data_process(seed)\n",
    "    print('降维前的svm的表现:')\n",
    "    _svm(X_train,y_train,X_valid, y_valid,X_test,y_test)\n",
    "    print('降维后svm的表现:')\n",
    "\n",
    "    X=np.concatenate((X_train,X_valid,X_test),axis=0)\n",
    "    y=np.concatenate((y_train,y_valid,y_test),axis=0)\n",
    "    X_reduced=dimension_reduction(X,y,dim=120,method='PCA')\n",
    "    X_train_reduced=X_reduced[:X_train.shape[0],:]\n",
    "    X_valid_reduced=X_reduced[X_train.shape[0]:X_train.shape[0]+X_valid.shape[0],:]\n",
    "    X_test_reduced=X_reduced[X_train.shape[0]+X_valid.shape[0]:,:]\n",
    "\n",
    "    # X_train_reduced=dimension_reduction(X_train_reduced,y_train,dim=30,method='Laplacian')\n",
    "    # X_train_reduced,proj_mat=dimension_reduction(X_train_reduced,y_train,dim=1,method='LDA')\n",
    "    # visualization(X_train_reduced,y_train,dim=dim,method='PCA',class_num=2)\n",
    "    # X_test_reduced=dimension_reduction(X_test,y_test,dim=2,method='Isomap')\n",
    "    # X_test_reduced=dimension_reduction(X_test_reduced,y_test,dim=30,method='Laplacian')\n",
    "    # X_test_reduced=np.dot(X_test_reduced,proj_mat)\n",
    "    # visualization(X_test_reduced,y_test,dim=dim,method='PCA',class_num=2)\n",
    "    # _svm(X_train_reduced,y_train,X_test_reduced,y_test)\n",
    "    train_acc,valid_acc,test_acc=_svm(X_train_reduced,y_train,X_valid_reduced,y_valid,X_test_reduced,y_test)\n",
    "    train_accs.append(train_acc)\n",
    "    valid_accs.append(valid_acc)\n",
    "    test_accs.append(test_acc)\n",
    "print('train_accs:',train_accs)\n",
    "print('valid_accs:',valid_accs)\n",
    "print('test_accs:',test_accs)\n",
    "print('train_acc:',np.mean(train_accs),np.std(train_accs))\n",
    "print('valid_acc:',np.mean(valid_accs),np.std(valid_accs))\n",
    "print('test_acc:',np.mean(test_accs),np.std(test_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
